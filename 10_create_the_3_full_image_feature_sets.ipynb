{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indie-image",
   "metadata": {},
   "source": [
    "# Create the Full Image Feature Sets\n",
    "In this notebook we generate the feature dataset from thumbnail sized copies of the full Artwork image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unusual-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=r\"Passing\", category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import tensorflow_hub as hub\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from numpy import savez_compressed\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outer-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off tensorflow INFO messages\n",
    "tf.logging.set_verbosity(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "important-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define array names used in tile feature files\n",
    "FEATURES     = \"arr_0\"\n",
    "TILE_TAGS    = \"arr_1\"\n",
    "IMAGE_TAGS   = \"arr_2\"\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "relevant-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define file paths\n",
    "data_file_path     = \"./data/\"\n",
    "image_file_path    = \"\".join([data_file_path, \"images/\"])  \n",
    "feature_sets       = \"\".join([data_file_path, \"full_image_feature_sets/\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-pearl",
   "metadata": {},
   "source": [
    "## Connect to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "electric-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DB connection between python and the file system\n",
    "conn = sqlite3.connect(''.join([data_file_path,\"/database/artist.db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-gardening",
   "metadata": {},
   "source": [
    "## Spliting the Datasets into __Train__, __Test__ & __Validation__ Subsets\n",
    "Both _genre_ & _artist_ feature sets have __3306__ entries. But, the _style_ feature set has __3742__. This is because an artwork may have more than one sytle associated with it. To allow the _feature sets_ to be split into _train_, _test_ & _validation_ subsets the _image_tag_ must be used to decide the final set detination. Here we perfor a double _train_test_split_ to achieve a splt ratio of approx: __70%__, __20%__ & __10%__.\n",
    "<br/>\n",
    "Create a simple query against the RDBMS to return a list of all _IMAGE_TAGs_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abstract-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: select a list of unique image tags\n",
    "query_string = \"\"\"\n",
    "SELECT IMAGE_TAG\n",
    "FROM   ARTWORK_IMAGE\n",
    "\"\"\"\n",
    "\n",
    "# create the results dataframe\n",
    "i_tags = pd.read_sql_query(query_string, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-insurance",
   "metadata": {},
   "source": [
    "Perform two random data splits to create the __TRAIN, TEST__ & __VALIDATE__ datasets selection in the approximate sizes : _70%_, _20%_ & _10%_. <br/> __NOTE:__ This is just the selection of which images will be assigned to the three sets. This results in three lists of __IMAGE_TAGS__. The actual creation of the datasets happens further down the notebook. <br/>__NOTE:__ The splits are kept consistence with the use of the <code>RANDOM_STATE</code> being set throughout the project to value: __42__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sonic-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the list of image tags into 3 sets:\n",
    "# train    ~70%\n",
    "# test     ~20%\n",
    "# validate ~10%\n",
    "\n",
    "# using the train test split we first extract our taining set which leaves a remainder\n",
    "train_tags   , remainder_tags, _, _ = train_test_split(i_tags        , i_tags        , test_size = 0.3, random_state = RANDOM_STATE)\n",
    "\n",
    "# now the reaminder is is split into a test and a validation set\n",
    "validate_tags, test_tags     , _, _ = train_test_split(remainder_tags, remainder_tags, test_size = 0.7, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-definition",
   "metadata": {},
   "source": [
    "Convert the three dataset selections into Numpy Arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gross-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reduce the search lookup process time we convert \n",
    "# the dataframes into numpy arrays\n",
    "train_tags    = train_tags[   \"image_tag\"].to_numpy()\n",
    "test_tags     = test_tags[    \"image_tag\"].to_numpy()\n",
    "validate_tags = validate_tags[\"image_tag\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-tracker",
   "metadata": {},
   "source": [
    "Set the feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tropical-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define module URL\n",
    "module_url = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_96/feature_vector/3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-horror",
   "metadata": {},
   "source": [
    "The function <code>get_image_features()</code> opens the image. Resizes it and then using the feature extractor module <code>https://tfhub.dev/google/imagenet/mobilenet_v2_100_96/feature_vector/3</code>, it extracts the images features.<br/>\n",
    "__NOTE:__ The feature extraction process is run on the GPU device <code>/device:GPU:0</code>. (_Just as an experiment_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hindu-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to extract features\n",
    "def get_image_features(image_path):\n",
    "\n",
    "    # resize to a small square image\n",
    "    resized_image = Image.open(image_path).resize((96, 96), Image.ANTIALIAS)\n",
    "    \n",
    "    # convert the image to RGB and then to a numpy array\n",
    "    img_batch     = np.array(resized_image.convert('RGB'), dtype = np.float32)[np.newaxis, :, :, :]/255\n",
    "\n",
    "    # create graph\n",
    "    img_graph     = tf.Graph()\n",
    "    \n",
    "    # define nvidia GPU as processing device\n",
    "    with tf.device('/device:GPU:0'):\n",
    "\n",
    "        # extract the image features\n",
    "        with img_graph.as_default():\n",
    "\n",
    "            feature_extractor = hub.Module(module_url)\n",
    "\n",
    "            # create input placeholder\n",
    "            input_imgs = tf.placeholder(dtype=tf.float32, shape=[None, 96, 96, 3])\n",
    "\n",
    "            # a node with the features\n",
    "            imgs_features = feature_extractor(input_imgs)\n",
    "\n",
    "            # collect initializers\n",
    "            init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "\n",
    "        img_graph.finalize() \n",
    "\n",
    "        # create a session\n",
    "        sess = tf.Session(graph=img_graph)\n",
    "\n",
    "        # initialize it\n",
    "        sess.run(init_op)\n",
    "\n",
    "        # extract features\n",
    "        features = sess.run(imgs_features, feed_dict={input_imgs: img_batch})\n",
    "    \n",
    "        # return the features\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-distance",
   "metadata": {},
   "source": [
    "## Build the __Genre__ Feature Set Arrays\n",
    "\n",
    "Query the RDBMS to return a list of all __IMAGE_TAG__ values and the associated __GENRE__ catagories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alien-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define query\n",
    "query_string = \"\"\"\n",
    "SELECT IMAGE_TAG,\n",
    "       GENRE\n",
    "FROM   GENRE         AS A,\n",
    "       ARTWORK       AS B,\n",
    "       ARTWORK_IMAGE AS C\n",
    "WHERE  A.ID = B.GENRE_ID\n",
    "AND    B.ID = C.ARTWORK_ID\n",
    "\"\"\"\n",
    "    \n",
    "# execute query\n",
    "genre_query_result = pd.read_sql_query(query_string, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-marshall",
   "metadata": {},
   "source": [
    "Here we loop through every every __IMAGE_TAG__ and identify if the image feature data should be in the __TRAIN, TEST__ or __VALIDATE__ dataset. Once the correct destination has been identified. The data is added to a set of array and finally written to one of three compressed data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "positive-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature set arrays\n",
    "features_tr  = []\n",
    "features_te  = []\n",
    "features_va  = []\n",
    "genre_tr     = []\n",
    "genre_te     = []\n",
    "genre_va     = []\n",
    "image_tag_tr = []\n",
    "image_tag_te = []\n",
    "image_tag_va = []\n",
    "\n",
    "# loop through selection rows\n",
    "for index, row in genre_query_result.iterrows():\n",
    "\n",
    "    #read image \n",
    "    image_path     = \"\".join([image_file_path, \"full_image_\", row[\"image_tag\"] ,\".jpg\"])\n",
    "\n",
    "    # call the helper function to extract the features\n",
    "    image_features = get_image_features(image_path)\n",
    "        \n",
    "    # check in smallest dataset and then second \n",
    "    # smallest dataset for speed\n",
    "    if row[\"image_tag\"] in validate_tags:\n",
    "        # append data to feature set arrays\n",
    "        features_va.append(image_features   )\n",
    "        genre_va.append(    row[\"genre\"]    )\n",
    "        image_tag_va.append(row[\"image_tag\"])\n",
    "    elif row[\"image_tag\"] in test_tags:\n",
    "        # append data to feature set arrays\n",
    "        features_te.append(image_features   )\n",
    "        genre_te.append(    row[\"genre\"]    )\n",
    "        image_tag_te.append(row[\"image_tag\"])\n",
    "    else:\n",
    "        # append data to feature set arrays\n",
    "        features_tr.append(image_features   )\n",
    "        genre_tr.append(    row[\"genre\"]    )\n",
    "        image_tag_tr.append(row[\"image_tag\"])\n",
    "    \n",
    " # write files\n",
    "savez_compressed(\"\".join([feature_sets,\"genre_train_features\"    ]),  features_tr, genre_tr, image_tag_tr)\n",
    "savez_compressed(\"\".join([feature_sets,\"genre_test_features\"     ]),  features_te, genre_te, image_tag_te)\n",
    "savez_compressed(\"\".join([feature_sets,\"genre_validation_features\"]), features_va, genre_va, image_tag_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-safety",
   "metadata": {},
   "source": [
    "## Build the __Style__ Feature Set Arrays\n",
    "\n",
    "Query the RDBMS to return a list of all __IMAGE_TAG__ values and the associated __STYLE__ catagories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "continental-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we generate additonal records here becaus an artwork can be listed with more than one style\n",
    "query_string = \"\"\"\n",
    "SELECT IMAGE_TAG,\n",
    "       STYLE\n",
    "FROM   STYLE         AS A,\n",
    "       ARTWORK_STYLE AS B,\n",
    "       ARTWORK_IMAGE AS C\n",
    "WHERE   B.STYLE_ID  = A.ID   \n",
    "AND    C.ARTWORK_ID = B.ARTWORK_ID\n",
    "\"\"\"\n",
    "    \n",
    "style_query_result = pd.read_sql_query(query_string, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-mount",
   "metadata": {},
   "source": [
    "Here we loop through every every __IMAGE_TAG__ and identify if the image feature data should be in the __TRAIN, TEST__ or __VALIDATE__ dataset. Once the correct destination has been identified. The data is added to a set of array and finally written to one of three compressed data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mechanical-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature set arrays\n",
    "features_tr  = []\n",
    "features_te  = []\n",
    "features_va  = []\n",
    "style_tr     = []\n",
    "style_te     = []\n",
    "style_va     = []\n",
    "image_tag_tr = []\n",
    "image_tag_te = []\n",
    "image_tag_va = []\n",
    "\n",
    "# loop through selection rows\n",
    "for index, row in style_query_result.iterrows():\n",
    "\n",
    "    #read image \n",
    "    image_path     = \"\".join([image_file_path, \"full_image_\", row[\"image_tag\"] ,\".jpg\"])\n",
    "    \n",
    "    # call the helper function to extract the features\n",
    "    image_features = get_image_features(image_path)\n",
    "\n",
    "    # check in smallest dataset and then second \n",
    "    # smallest dataset for speed\n",
    "    if row[\"image_tag\"] in validate_tags:\n",
    "       # append data to feature set arrays\n",
    "        features_va.append(image_features   )\n",
    "        style_va.append(    row[\"style\"]    )\n",
    "        image_tag_va.append(row[\"image_tag\"])\n",
    "    elif row[\"image_tag\"] in test_tags:\n",
    "        # append data to feature set arrays\n",
    "        features_te.append(image_features   )\n",
    "        style_te.append(    row[\"style\"]    )\n",
    "        image_tag_te.append(row[\"image_tag\"])\n",
    "    else:\n",
    "        # append data to feature set arrays\n",
    "        features_tr.append(image_features   )\n",
    "        style_tr.append(    row[\"style\"]    )\n",
    "        image_tag_tr.append(row[\"image_tag\"])\n",
    "    \n",
    " # write files\n",
    "savez_compressed(\"\".join([feature_sets,\"style_train_features\"    ]),  features_tr, style_tr, image_tag_tr)\n",
    "savez_compressed(\"\".join([feature_sets,\"style_test_features\"     ]),  features_te, style_te, image_tag_te)\n",
    "savez_compressed(\"\".join([feature_sets,\"style_validation_features\"]), features_va, style_va, image_tag_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-savage",
   "metadata": {},
   "source": [
    "## Build the __Artist__ Feature Set Arrays\n",
    "\n",
    "Query the RDBMS to return a list of all __IMAGE_TAG__ values and the associated __ARTIST__ names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prescribed-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we generate additonal records here becaus an artwork can be listed with more than one style\n",
    "query_string = \"\"\"\n",
    "SELECT IMAGE_TAG,\n",
    "       NAME\n",
    "FROM   ARTWORK       AS A,\n",
    "       ARTIST        AS B,\n",
    "       ARTWORK_IMAGE AS C\n",
    "WHERE  A.ARTIST_ID = B.ID   \n",
    "AND    A.ID        = C.ARTWORK_ID\n",
    "\"\"\"\n",
    "    \n",
    "artist_query_result = pd.read_sql_query(query_string, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-slovakia",
   "metadata": {},
   "source": [
    "Here we loop through every every __IMAGE_TAG__ and identify if the image feature data should be in the __TRAIN, TEST__ or __VALIDATE__ dataset. Once the correct destination has been identified. The data is added to a set of array and finally written to one of three compressed data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "essential-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature set arrays\n",
    "features_tr  = []\n",
    "features_te  = []\n",
    "features_va  = []\n",
    "artist_tr    = []\n",
    "artist_te    = []\n",
    "artist_va    = []\n",
    "image_tag_tr = []\n",
    "image_tag_te = []\n",
    "image_tag_va = []\n",
    "\n",
    "# loop through selection rows\n",
    "for index, row in artist_query_result.iterrows():\n",
    "\n",
    "    #read image \n",
    "    image_path     = \"\".join([image_file_path, \"full_image_\", row[\"image_tag\"] ,\".jpg\"])\n",
    "\n",
    "    # call the helper function to extract the features\n",
    "    image_features = get_image_features(image_path)\n",
    "    \n",
    "    # check in smallest dataset and then second \n",
    "    # smallest dataset for speed\n",
    "    if row[\"image_tag\"] in validate_tags:\n",
    "        # append data to feature set arrays\n",
    "        features_va.append(image_features   )\n",
    "        artist_va.append(   row[\"name\"]     )\n",
    "        image_tag_va.append(row[\"image_tag\"])\n",
    "    elif row[\"image_tag\"] in test_tags:\n",
    "        # append data to feature set arrays\n",
    "        features_te.append(image_features   )\n",
    "        artist_te.append(   row[\"name\"]     )\n",
    "        image_tag_te.append(row[\"image_tag\"])\n",
    "    else:\n",
    "        # append data to feature set arrays\n",
    "        features_tr.append(image_features   )\n",
    "        artist_tr.append(   row[\"name\"]     )\n",
    "        image_tag_tr.append(row[\"image_tag\"])\n",
    "    \n",
    " # write files\n",
    "savez_compressed(\"\".join([feature_sets,\"artist_train_features\"    ]),  features_tr, artist_tr, image_tag_tr)\n",
    "savez_compressed(\"\".join([feature_sets,\"artist_test_features\"     ]),  features_te, artist_te, image_tag_te)\n",
    "savez_compressed(\"\".join([feature_sets,\"artist_validation_features\"]), features_va, artist_va, image_tag_va)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
