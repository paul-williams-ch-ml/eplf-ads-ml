{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Painting Details Scraping\n",
    "In this section we define the artists that we wish to use in the project and then scrape the text-based data. <br/>\n",
    "__NOTE:__ There is no special reason that I chose these Artists. But points that I considered were; different _genres_ & _styles_. The _period_ in which they produced artworks (_not to have Artists all from the same period in time_). The number of pieces of art (_to few would not provide enough data for analysis, too many prove to be impractical considering the processing power needed_). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Artists\n",
    "It would be nice to process the data from all artists displayed on the _WikiArt_ website. But, Time & Processing constraints prevent this. Therefore a small sellection of Artists have been chosen for this project. The selecttion vas based on this criteria: <br/>\n",
    "- They have at least one artworks on the WikiArt website that I liked.\n",
    "- Collectively they provide a range of Styles and Genres.\n",
    "- Collectively they produced their works at different time periods.\n",
    "- I did not want artists that only have 2 or 3 artworks listed.\n",
    "- I did not want lots of artists with very large collections. _(Limitations in processing power/time to consider)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTISTS = [\"piet-mondrian\",\n",
    "           \"berthe-morisot\",\n",
    "           \"tamara-de-lempicka\",\n",
    "           \"katsushika-hokusai\",\n",
    "           \"m-c-escher\",\n",
    "           \"l-s-lowry\",\n",
    "           \"roy-lichtenstein\",\n",
    "           \"jackson-pollock\",\n",
    "           \"edward-hicks\",\n",
    "           \"agnes-martin\",\n",
    "           \"pablo-picasso\",\n",
    "           \"francisco-goya\",\n",
    "           \"henry-fuseli\",\n",
    "           \"karl-bodmer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function to Extract the URL of the Artwork Image\n",
    "We read the _HTML_ of webpage containing the Artists cataloged images and extract the individual _URLs_ for each art piece. <br/>\n",
    "<img src=\"./images/web_scrape2.png\" width=\"1280px\"><br/>\n",
    "__NOTE:__ Above we see a screen grab of the _Developer Tools_ view of an artists catalog. It is possble to scrape the data directly from the webpages HTML code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_painting_urls_for_artist(artist):\n",
    "\n",
    "    # create an empty list to store the URLs \n",
    "    url_list = []\n",
    "\n",
    "    # construct the URL\n",
    "    url      = \"https://www.wikiart.org/en/{}/all-works/text-list\".format(artist)\n",
    "    \n",
    "    # GET the website HTML source\n",
    "    page     = requests.get(url)\n",
    "\n",
    "    # extract HTML\n",
    "    soup     = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "    # find all <a> tags within the HTML and loop through them\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        \n",
    "        # select only those with the artists name that do not contaian a target attribue\n",
    "        if \"en/{}\".format(artist) in str(a_tag) and \"target\" not in str(a_tag):\n",
    "            \n",
    "            # contract the url of the page containing the image ref URL and details\n",
    "            url_list.append(\"https://www.wikiart.org{}\".format(a_tag[\"href\"]))\n",
    "            \n",
    "    # return the full list of formatted URLs\n",
    "    return(url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function to Extract the Text Based Data About the Image\n",
    "From the _HTML_ of the webpage detailing the individual artworks we extract the _text_ data and the _URL_ of the artworks image file. <br/>\n",
    "<img src=\"./images/web_scrape1.png\" width=\"1280px\"><br/>\n",
    "__NOTE:__ Above we see a screen grab of the _Developer Tools_ view of an artworks page. It is possible to scrape both the _Text_ data and the artwork image files URL from the webpages HTML code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_painting_details(url):\n",
    "    \n",
    "    # GET the website HTML source    \n",
    "    page         = requests.get(url)\n",
    "\n",
    "    # extract HTML\n",
    "    soup         = BeautifulSoup(page.text, \"lxml\")\n",
    "\n",
    "    # define variables\n",
    "    image_url    = \"\"\n",
    "    image_style  = \"\"\n",
    "    image_genre  = \"\"\n",
    "    image_media  = \"\"\n",
    "    image_title  = \"\"\n",
    "    image_year   = \"\"\n",
    "    image_artist = \"\"\n",
    "    \n",
    "    # find the image tag\n",
    "    try:\n",
    "        image_tag = soup.find(\"img\")\n",
    "        image_url = image_tag[\"src\"]\n",
    "    # NOTE: in the event of there being an error reading the HTML just exit try block and use the default empty string\n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "    # find the artical tag to extract title, artist and year \n",
    "    try:\n",
    "        article_tag  = soup.find(\"article\")\n",
    "\n",
    "        # extract just the text to give the title\n",
    "        image_title  = article_tag.find(\"h3\").text\n",
    "    \n",
    "        # extract just the text to give the artist\n",
    "        image_artist = article_tag.find(\"a\").text\n",
    "    \n",
    "        # extract just the text to give the year\n",
    "        li_tag       = article_tag.find(\"li\", class_ = '')\n",
    "        image_year   = li_tag.find(\"span\").text[0:4]\n",
    "    # NOTE: in the event of there being an error reading the HTML just exit try block and use the default empty string\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # clean up the list tag and extract text \n",
    "    try:\n",
    "        li_tag = soup.find_all(\"li\", class_ = 'dictionary-values')\n",
    "\n",
    "        # loop through all items in the list\n",
    "        for li_item in li_tag:\n",
    "        \n",
    "            try:\n",
    "                # for each list item identify the <p> tag and extract the text\n",
    "                item_text       = BeautifulSoup(li_item.text, \"lxml\")\n",
    "                item_p_tag_text = item_text.find(\"p\")\n",
    "    \n",
    "                # clean line breaks, convert to lowercase and split field name from field value(s)\n",
    "                field_name, field_value = str(item_p_tag_text.text).strip().replace('\\r', '').replace('\\n', '').lower().split(\":\")\n",
    "        \n",
    "                # assign relivant value to field\n",
    "                if field_name == \"style\" : image_style = field_value\n",
    "                if field_name == \"genre\" : image_genre = field_value\n",
    "                if field_name == \"media\" : image_media = field_value\n",
    "            # NOTE: in the event of there being an error reading the HTML just exit try block and use the default empty string\n",
    "            except:\n",
    "                pass        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # return a dictionary of all extracted values  \n",
    "    return({\"title\"  : image_title,\n",
    "            \"year\"   : image_year,\n",
    "            \"artist\" : image_artist,\n",
    "            \"style\"  : image_style,\n",
    "            \"genre\"  : image_genre,\n",
    "            \"media\"  : image_media,\n",
    "            \"url\"    : image_url})      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Artwork Text Data\n",
    "We work through the list of chosen Artists. We first find the web page containing the calalog of their artworks and then, using the information that we have gathered, we more th the web page of the individual work of art and extract the data that we require. Once we have the information, we store it as a collection of _.csv_ files, one per artist, for further use in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [03/0104]"
     ]
    }
   ],
   "source": [
    "# initialize the artist counter\n",
    "artist_counter = 1\n",
    "\n",
    "# loop through out list of artists\n",
    "for artist in ARTISTS:\n",
    "    \n",
    "    # create a dataframe for details of the current artist\n",
    "    df_artist_works_of_art = pd.DataFrame()\n",
    "    \n",
    "    # initialize the artwork counter \n",
    "    artwork_counter = 1\n",
    "\n",
    "    # get a list of the artists works and loop through them\n",
    "    for work_of_art_details in get_painting_urls_for_artist(artist):\n",
    "        \n",
    "        # output progress\n",
    "        sys.stdout.write(f\"\\rProcessing [{str(artist_counter).zfill(2)}/{str(artwork_counter).zfill(4)}]\")\n",
    "        \n",
    "        # call our helper function to extract details for the specific picture\n",
    "        df_artist_works_of_art = df_artist_works_of_art.append(eval(str(get_painting_details(work_of_art_details))), ignore_index = True)\n",
    "        \n",
    "        # increment artwork counter\n",
    "        artwork_counter += 1\n",
    "    \n",
    "    # write the dataframe of the artists work to a csv (Charater Seperated Fields - ';' as commas are used in some fields)\n",
    "    df_artist_works_of_art.to_csv(\"\".join([\"./data/artists/\", artist, \".csv\"]), sep = \";\" )\n",
    "                                                            \n",
    "    # increment artist counter\n",
    "    artist_counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
